{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4089966",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center;border-radius:20px ;border:3px solid #c54E58 ;color : white;  padding: 15px; font-size: 15pt; background-color:blue'>DESIGN AND DEVELOPMENT OF A WEB-BASED BANK CUSTOMER CHURN PREDICTION PLATFORM USING ADVANCED MACHINE LEARNING MODELS TO ENHANCE CUSTOMER RETENTION STRATEGIES AND USER EXPERIENCE</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb26b7",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:20px ;border:3px solid red ;color : Blue;  padding: 15px; font-size: 14pt; background-color: ; text-align:left\">\n",
    "\n",
    "This project aims to predict customer churn in banks, helping institutions identify at-risk customers and improve retention. By analyzing factors like credit scores, account balances, and customer activity, the model will provide insights to enhance loyalty strategies.\n",
    "\n",
    "Using Python and machine learning, the project will develop a predictive model based on historical customer data. Feature engineering, exploratory data analysis (EDA), and visualization techniques will reveal key churn patterns. Advanced models, including ensemble learning, will ensure high accuracy.\n",
    "\n",
    "The final output will be a web-based platform where banks can input customer data, receive churn predictions, and access retention recommendations. With real-time insights, banks can improve customer experience, reduce attrition, and optimize retention strategies.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e7918e",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:20px ;border:3px solid red ;color : blue; padding: 15px; background-color: rgba(135, 206, 235, 0.4); text-align:left\"> <a id=\"met\"></a> <h2> Methodology for Analyzing Features</h2>\n",
    "    \n",
    "The methodology for analyzing features in this bank customer churn prediction project follows a structured approach to uncover key patterns and factors influencing customer attrition.\n",
    "\n",
    "* **Data Overview:**\n",
    "\n",
    "    - Inspect dataset for missing values, duplicates, and inconsistencies.\n",
    "    - Analyze distributions of key features like credit scores, account balances, and tenure.\n",
    "    - Identify outliers and assess data quality.\n",
    "    \n",
    "* **Feature Categorization:**\n",
    "\n",
    "    - Classify features into demographic (e.g., age, gender, country), financial (e.g., balance, estimated salary), and engagement-related (e.g., active member status, number of products used).\n",
    "    \n",
    "* **Formulate Hypotheses:**\n",
    "\n",
    "    - Define the null hypothesis (H0): There is no significant relationship between customer demographics, financial behaviors, and churn.\n",
    "    - Test hypotheses to determine the strongest churn predictors.\n",
    "\n",
    "* **Statistical Analysis:**\n",
    "\n",
    "    - Correlation Analysis to assess relationships between numerical variables like credit score, account balance, and churn probability.\n",
    "    - Chi-square tests for categorical variables to evaluate their association with churn.\n",
    "    \n",
    "* **Visual Analysis:**\n",
    "\n",
    "    - Use heatmaps, bar charts, and scatter plots to explore trends in customer churn.\n",
    "    - Box plots and histograms to detect skewness and distribution of key numerical features.\n",
    "    \n",
    "* **Observations & Insights:**\n",
    "\n",
    "    - Summarize key findings from statistical and visual analyses.\n",
    "    - Identify the most influential features driving customer churn for model training.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89acb47e",
   "metadata": {},
   "source": [
    "# <div style=\"padding:20px;color:white;margin:0;font-size:35px;text-align:center;display:fill;border-radius:10px;background-color:#c54E58;overflow:hidden; font-family: 'Lucida Console'\"><b> DATA OVERVIEW </b></div>\n",
    "<a id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0385ba7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _errors: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chi2_contingency\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resample\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SelectKBest, f_classif, mutual_info_classif\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# DO NOT EDIT. Generated by api_gen.sh\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTypePolicy\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FloatDTypePolicy\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Function\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\api\\__init__.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m regularizers\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\api\\saving\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_editor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasFileEditor\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_registration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomObjectScope\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_registration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     CustomObjectScope \u001b[38;5;28;01mas\u001b[39;00m custom_object_scope,\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\file_editor.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrich\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconsole\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:25\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# --- Library setup -----------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# When importing from the root of the unpacked tarball or git checkout,\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Python sees the \"h5py\" source directory and tries to load it, which fails.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# We tried working around this by using \"package_dir\" but that breaks Cython.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _errors\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_op\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _errors: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# For visualization\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder, LabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import optuna\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Classification metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4596ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into the DataFrame as df\n",
    "df = pd.read_csv(\"Bank Customer Churn Prediction.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the dataset\n",
    "print(f\"Dataframe dimensions: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2cd45c",
   "metadata": {},
   "source": [
    "The dataset contains 10,000 rows entries and 12 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caaa361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Additional information about the columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbba50b",
   "metadata": {},
   "source": [
    "There are no \"nulls\" in our dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333732fd",
   "metadata": {},
   "source": [
    "#### Summary statistics for the numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a8008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further statistical description of the dataset, givingthe mean, std, IQR, min & max values for each column\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c725864",
   "metadata": {},
   "source": [
    "From the summary statistics we can conclude that all features look OK. We do not see any extreme values for any feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5749650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and unique values to confirm there are no unusual data entries or types\n",
    "df.dtypes  ,   df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3a72b",
   "metadata": {},
   "source": [
    "To make dataframe easily readable we will drop features not needed for machine learning (customer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d9439",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a726a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused features\n",
    "df.drop(['customer_id'], axis=1, inplace=True)\n",
    "print(f\"Dataframe dimensions: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39978742",
   "metadata": {},
   "source": [
    "### Distributions of Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram grid\n",
    "df.hist(figsize=(14,14))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760f708a",
   "metadata": {},
   "source": [
    "## Histogram Findings:\n",
    "Credit Score: Mostly normal around 600–700.\n",
    "\n",
    "Age: Skewed right; most are 30–40. Older customers may churn differently.\n",
    "\n",
    "Tenure: Evenly spread, but a spike at 10 years.\n",
    "\n",
    "Balance: Bimodal—many have zero balance, others cluster around 50K–150K. Zero balance might indicate inactivity.\n",
    "\n",
    "Products Number: Most have 1 or 2; few have 3+. Fewer products might mean higher churn.\n",
    "\n",
    "Active Member: Majority are active; inactivity might predict churn.\n",
    "\n",
    "Estimated Salary: Evenly spread, likely not a key churn factor.\n",
    "\n",
    "Churn: Imbalanced—most didn’t churn, but a significant minority did."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84710154",
   "metadata": {},
   "source": [
    "### Distributions of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize categorical features\n",
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d7d5ce",
   "metadata": {},
   "source": [
    "This shows us the number of unique classes for each feature. For example, there are more males (5457) than females. And France is most common of 3 geographies in our dataframe. There are no sparse classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac269ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for \"gender\"\n",
    "plt.figure(figsize=(4,4))\n",
    "df['gender'].value_counts().plot.bar(color=['b', 'g'])\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('gender')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "print(\"In our data sample there are more males than females.\")\n",
    "\n",
    "Counter(df.gender) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12414543",
   "metadata": {},
   "source": [
    "This bar chart shows the gender distribution of customers:\n",
    "\n",
    "Males outnumber females, but not by a huge margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b60335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for \"country\"\n",
    "plt.figure(figsize=(6,4))\n",
    "df['country'].value_counts().plot.bar(color=['b', 'g', 'r'])\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('country')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "Counter(df.country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726ababa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given distribution\n",
    "country_counts = Counter({'France': 5014, 'Spain': 2477, 'Germany': 2509})\n",
    "total_entries = sum(country_counts.values())\n",
    "\n",
    "# Calculate percentages rounded to 2 decimal places\n",
    "country_percentages = {country: round((count / total_entries) * 100, 2) for country, count in country_counts.items()}\n",
    "\n",
    "country_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f7a9f2",
   "metadata": {},
   "source": [
    "Majority of customers are from France with percentage of about 50%, and from Germany and Spain around 25% each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd22e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"churn\", data=df, palette=\"coolwarm\")\n",
    "plt.title(\"Churn Distribution\")\n",
    "plt.xlabel(\"Churn (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Numerical Features\n",
    "numerical_cols = ['credit_score', 'age', 'tenure', 'balance', 'products_number', 'estimated_salary']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(numerical_cols, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(df[col], bins=30, kde=True, color=\"blue\")\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1581a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of age vs churn\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x=\"churn\", y=\"age\", data=df, palette=\"coolwarm\")\n",
    "plt.title(\"Age Distribution by Churn Status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a433296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn rate by country\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x=\"country\", hue=\"churn\", data=df, palette=\"coolwarm\")\n",
    "plt.title(\"Churn Rate by Country\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58508a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn rate by active membership\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"active_member\", hue=\"churn\", data=df, palette=\"Set1\")\n",
    "plt.title(\"Churn Rate by Active Membership\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e29197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn rate by number of products\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"products_number\", hue=\"churn\", data=df, palette=\"Dark2\")\n",
    "plt.title(\"Churn Rate by Number of Products\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed19178",
   "metadata": {},
   "source": [
    "# <div style=\"padding:20px;color:white;margin:0;font-size:35px;text-align:center;display:fill;border-radius:10px;background-color:#c54E58;overflow:hidden; font-family: 'Lucida Console'\"><b> UNIVARIATE ANALYSIS</b></div>\n",
    "<a id=\"analysis\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4408321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Skewness & Kurtosis\n",
    "numerical_cols = ['credit_score', 'age', 'tenure', 'balance', 'products_number', 'estimated_salary']\n",
    "for col in numerical_cols:\n",
    "    skewness = df[col].skew()\n",
    "    kurtosis = df[col].kurt()\n",
    "    print(f\"{col}: Skewness = {skewness:.2f}, Kurtosis = {kurtosis:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f38892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Boxplots (Outliers Detection)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df[numerical_cols], palette=\"Set2\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Boxplot of Numerical Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Countplot for Categorical Features\n",
    "categorical_cols = [\"country\", \"gender\", \"credit_card\", \"active_member\", \"churn\"]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, col in enumerate(categorical_cols, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.countplot(x=df[col], palette=\"Pastel2\")\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6eff82",
   "metadata": {},
   "source": [
    "# <div style=\"padding:20px;color:white;margin:0;font-size:35px;text-align:center;display:fill;border-radius:10px;background-color:#c54E58;overflow:hidden; font-family: 'Lucida Console'\"><b>MULTIVARIATE ANALYSIS </b></div>\n",
    "<a id=\"multivariate\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae017ef0",
   "metadata": {},
   "source": [
    "## Color palette was set to \"deep\" for clearer visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f773c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pairplot (Numerical Variables & Churn)\n",
    "sns.pairplot(df, hue=\"churn\", vars=numerical_cols, palette=\"deep\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ba404b",
   "metadata": {},
   "source": [
    "This pair plot visualizes relationships between features, with churn (0 = stayed, 1 = left) color-coded. Key insights:\n",
    "\n",
    "Age & Churn: Higher churn among older customers.\n",
    "\n",
    "Balance & Churn: Churners seem to cluster in the mid-to-high balance range.\n",
    "\n",
    "Products Number & Churn: More churn in customers with 2+ products.\n",
    "\n",
    "Credit Score & Churn: No clear trend, churn is spread across scores.\n",
    "\n",
    "Estimated Salary & Churn: No strong correlation with churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Churn Rate by Age & Balance\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.scatterplot(x=df[\"age\"], y=df[\"balance\"], hue=df[\"churn\"], palette=\"deep\", alpha=0.6)\n",
    "plt.title(\"Age vs Balance by Churn Status\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a647332",
   "metadata": {},
   "source": [
    "This scatter plot shows Age vs. Balance, with churn status highlighted:\n",
    "\n",
    "## Key Insights:\n",
    "\n",
    "Higher churn (orange) in customers aged 40–60 with mid-to-high balances.\n",
    "\n",
    "Younger customers (<30) rarely churn, even with low balances.\n",
    "\n",
    "Churn is less common among elderly customers (70+).\n",
    "\n",
    "Many customers with zero balance don’t churn, possibly inactive but not exiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Categorical Feature Relationships (Cramér’s V)\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    return np.sqrt(chi2 / (n * (min(confusion_matrix.shape)-1)))\n",
    "\n",
    "print(\"\\nCramér’s V for Country & Churn:\", cramers_v(df[\"country\"], df[\"churn\"]))\n",
    "print(\"Cramér’s V for Gender & Churn:\", cramers_v(df[\"gender\"], df[\"churn\"]))\n",
    "print(\"Cramér’s V for Credit Card & Churn:\", cramers_v(df[\"credit_card\"], df[\"churn\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd745d2",
   "metadata": {},
   "source": [
    "Cramér’s V values indicate the strength of association between categorical variables and churn:\n",
    "\n",
    "**Country & Churn (0.1735)** → Weak but strongest influence among these three. Country might slightly impact churn.\n",
    "\n",
    "**Gender & Churn (0.1063)** → Very weak correlation; gender is not a strong churn predictor.\n",
    "\n",
    "**Credit Card & Churn (0.0069)** → Almost no correlation; credit card ownership doesn’t impact churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment \"churn\" by gender and display the frequency and percentage within each class\n",
    "grouped = df.groupby('gender')['churn'].agg(Count='value_counts')\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fbd57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage within each class\n",
    "dfgp = grouped.groupby(level=[0]).apply(lambda g: round(g * 100 / g.sum(), 2))\n",
    "dfgp.rename(columns={'Count': 'Percentage'}, inplace=True)\n",
    "dfgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae95d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize dataframe for plotting percentage\n",
    "dfgp = dfgp.pivot_table(values='Percentage', index='gender', columns=['churn'])\n",
    "dfgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5239eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize dataframe for plotting count\n",
    "dfgc = grouped\n",
    "dfgc = dfgc.pivot_table(values='Count', index='gender', columns=['churn'])\n",
    "dfgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9347e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn distribution by gender, count + percentage\n",
    "\n",
    "labels= ['Stays', 'Exits']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "dfgc.plot(kind='bar',\n",
    "          color=['g', 'r'],\n",
    "          rot=0, \n",
    "          ax=ax1)\n",
    "ax1.legend(labels)\n",
    "ax1.set_title('Churn Risk per Gender (Count)', fontsize=14, pad=10)\n",
    "ax1.set_ylabel('Count',size=12)\n",
    "ax1.set_xlabel('gender', size=12)\n",
    "\n",
    "\n",
    "dfgp.plot(kind='bar',\n",
    "          color=['g', 'r'],\n",
    "          rot=0, \n",
    "          ax=ax2)\n",
    "ax2.legend(labels)\n",
    "ax2.set_title('Churn Risk per Gender (Percentage)', fontsize=14, pad=10)\n",
    "ax2.set_ylabel('Percentage',size=12)\n",
    "ax2.set_xlabel('gender', size=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7cbb0",
   "metadata": {},
   "source": [
    "These charts compare churn rates between males and females:\n",
    "\n",
    "More males than females overall, but female customers churn at a higher rate (~25% vs. ~15%).\n",
    "\n",
    "Males are more likely to stay (higher retention percentage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c334a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment \"Exited\" by geography and display the frequency and percentage within each class\n",
    "grouped = df.groupby('country')['churn'].agg(Count='value_counts')\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad76292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize dataframe for plotting count\n",
    "dfgeoc = grouped\n",
    "dfgeoc = dfgeoc.pivot_table(values='Count', index='country', columns=['churn'])\n",
    "dfgeoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize dataframe for plotting count\n",
    "dfgeoc = grouped\n",
    "dfgeoc = dfgeoc.pivot_table(values='Count', index='country', columns=['churn'])\n",
    "dfgeoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bce0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage within each class\n",
    "dfgeop = grouped.groupby(level=[0]).apply(lambda g: round(g * 100 / g.sum(), 2))\n",
    "dfgeop.rename(columns={'Count': 'Percentage'}, inplace=True)\n",
    "dfgeop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af79a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn distribution by geography, count + percentage\n",
    "\n",
    "labels= ['Stays', 'Exits']\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, figsize=(12, 4))\n",
    "\n",
    "dfgeoc.plot(kind='bar',\n",
    "          color=['g', 'r'],\n",
    "          rot=0, \n",
    "          ax=ax1)\n",
    "ax1.legend(labels)\n",
    "ax1.set_title('Churn Risk per Country (Count)', fontsize=14, pad=10)\n",
    "ax1.set_ylabel('Count',size=12)\n",
    "ax1.set_xlabel('country', size=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8286d",
   "metadata": {},
   "source": [
    "## Distributions of the Target Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36618571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "df = pd.get_dummies(df, columns=[\"country\", \"gender\"], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638371aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features and Target\n",
    "X = df.drop(columns=[\"churn\"])  \n",
    "y = df[\"churn\"]\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212084d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Threshold (Removing low variance features)\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.01)  \n",
    "X_train_var = selector.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec6d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance using Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "feature_importances = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "# Plot Feature Importance\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=feature_importances, y=feature_importances.index, palette=\"coolwarm\")\n",
    "plt.title(\"Feature Importance using Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b0a3d8",
   "metadata": {},
   "source": [
    "## Feature Importance (Random Forest)\n",
    "Age is the most important factor in predicting churn. Older customers might be at higher risk.\n",
    "\n",
    "Estimated Salary, Credit Score, and Balance are also strong predictors.\n",
    "\n",
    "Number of Products & Tenure have moderate influence.\n",
    "\n",
    "Being an Active Member, Country, and Gender have lower impact.\n",
    "\n",
    "Credit Card ownership has minimal effect, confirming previous findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap Resampling to Balance Classes\n",
    "X_minority = X_train[y_train == 1] \n",
    "y_minority = y_train[y_train == 1]\n",
    "\n",
    "X_minority_resampled, y_minority_resampled = resample(\n",
    "    X_minority, y_minority, replace=True, \n",
    "    n_samples=len(X_train[y_train == 0]), \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine back with majority class\n",
    "X_train_resampled = np.vstack((X_train[y_train == 0], X_minority_resampled))\n",
    "y_train_resampled = np.hstack((y_train[y_train == 0], y_minority_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b637d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Countplot for Categorical Features\n",
    "categorical_cols = [\"credit_card\", \"active_member\", \"churn\"]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, col in enumerate(categorical_cols, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.countplot(x=df[col], palette=\"Pastel2\")\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Separate the majority and minority class\n",
    "df_majority = df[df['churn'] == 0]\n",
    "df_minority = df[df['churn'] == 1]\n",
    "\n",
    "\n",
    "# 3. **Hybrid Approach**: Balance with both over- and under-sampling\n",
    "df_majority_reduced = resample(df_majority, \n",
    "                               replace=False, \n",
    "                               n_samples=int(len(df_majority) * 0.5),  # Reduce majority class\n",
    "                               random_state=42)\n",
    "\n",
    "df_minority_increased = resample(df_minority, \n",
    "                                 replace=True, \n",
    "                                 n_samples=int(len(df_minority) * 1.5),  # Increase minority class\n",
    "                                 random_state=42)\n",
    "\n",
    "# Create new balanced datasets\n",
    "df_balanced_hybrid = pd.concat([df_majority_reduced, df_minority_increased])  # Hybrid approach\n",
    "\n",
    "# # Save the new dataset\n",
    "# df_balanced_oversample.to_csv(\"balanced_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Dataset balancing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd902997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original dataset\n",
    "df_original =  pd.read_csv(\"Bank Customer Churn Prediction.csv\")\n",
    "\n",
    "# Load the balanced dataset (change filename based on the method used)\n",
    "df_balanced = pd.read_csv(\"balanced_dataset.csv\")\n",
    "\n",
    "# Set up the figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Original dataset distribution\n",
    "sns.countplot(x='churn', data=df_original, palette=\"pastel\", ax=axes[0])\n",
    "axes[0].set_title(\"Original Dataset Distribution\")\n",
    "axes[0].set_xlabel(\"Churn\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "\n",
    "# Balanced dataset distribution\n",
    "sns.countplot(x='churn', data=df_balanced, palette=\"pastel\", ax=axes[1])\n",
    "axes[1].set_title(\"Balanced Dataset Distribution\")\n",
    "axes[1].set_xlabel(\"Churn\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7b1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Features \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90a9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "# 1. Histogram of Scaled Features\n",
    "def plot_histograms(data, title=\"Feature Distributions After Standardization\"):\n",
    "    data.hist(figsize=(12, 8), bins=30, edgecolor='black')\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "plot_histograms(X_train_scaled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb06c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef51b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Models\n",
    "models = {\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Neural Network (MLP)\": MLPClassifier(hidden_layer_sizes=(64,32), max_iter=500, random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1497945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Evaluate Models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Fit the model\n",
    "    if name == \"Neural Network (MLP)\":\n",
    "        model.fit(X_train_scaled, y_train_resampled)  # Scaled input for MLP\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train_resampled, y_train_resampled)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    results[name] = [accuracy, precision, recall, f1, auc]\n",
    "    \n",
    "    print(f\"{name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, AUC-ROC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results, index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"AUC-ROC\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Model Performance\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=results_df.index, y=results_df[\"AUC-ROC\"], palette=\"coolwarm\")\n",
    "plt.ylabel(\"AUC-ROC Score\")\n",
    "plt.title(\"Model Performance Comparison (AUC-ROC)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a0d6f9",
   "metadata": {},
   "source": [
    "## Model Performance Comparison (AUC-ROC Score)\n",
    "\n",
    "LightGBM performs the best, closely followed by CatBoost and Random Forest.\n",
    "\n",
    "XGBoost also performs well, slightly below the top models.\n",
    "\n",
    "Neural Network (MLP) has the lowest AUC-ROC score, suggesting it may not be the best fit for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff18d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Best Model\n",
    "best_model = results_df[\"AUC-ROC\"].idxmax()\n",
    "print(f\"\\nBest Model: {best_model} with AUC-ROC Score: {results_df.loc[best_model, 'AUC-ROC']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45bdfa",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna for Hyperparameter Tuning\n",
    "import lightgbm as lgb\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 50),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0)\n",
    "    }\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab256100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna Optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Best Parameters from Optuna\n",
    "best_params_optuna = study.best_params\n",
    "print(\"\\nBest Parameters (Optuna):\", best_params_optuna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14274e45",
   "metadata": {},
   "source": [
    "## Training the Best Balanced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ddcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Best Optuna Model\n",
    "best_lgb_optuna = lgb.LGBMClassifier(**best_params_optuna)\n",
    "best_lgb_optuna.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_optuna = best_lgb_optuna.predict(X_test)\n",
    "y_proba_optuna = best_lgb_optuna.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate Optuna Model\n",
    "accuracy_optuna = accuracy_score(y_test, y_pred_optuna)\n",
    "precision_optuna = precision_score(y_test, y_pred_optuna)\n",
    "recall_optuna = recall_score(y_test, y_pred_optuna)\n",
    "f1_optuna = f1_score(y_test, y_pred_optuna)\n",
    "auc_optuna = roc_auc_score(y_test, y_proba_optuna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a6d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nOptuna Tuned LightGBM - Accuracy: {accuracy_optuna:.4f}, Precision: {precision_optuna:.4f}, Recall: {recall_optuna:.4f}, F1-Score: {f1_optuna:.4f}, AUC-ROC: {auc_optuna:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c386a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot AUC-ROC Curve\n",
    "def plot_roc_curve(y_test, y_proba):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Call the functions using your Optuna model's predictions\n",
    "plot_confusion_matrix(y_test, y_pred_optuna)\n",
    "plot_roc_curve(y_test, y_proba_optuna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d2a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Load dataset (Assuming df is preloaded and cleaned)\n",
    "# Define Features and Target\n",
    "X = df.drop(columns=[\"churn\"])\n",
    "y = df[\"churn\"]\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize Models\n",
    "models = {\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Neural Network (MLP)\": MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred),\n",
    "        \"ROC AUC\": roc_auc_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# Step 1: Train on Imbalanced Dataset\n",
    "imbalanced_results = {name: evaluate_model(model, X_train, y_train, X_test, y_test) for name, model in models.items()}\n",
    "\n",
    "# Step 2: Balance Dataset using Bootstrap Resampling\n",
    "X_minority = X_train[y_train == 1]\n",
    "y_minority = y_train[y_train == 1]\n",
    "X_minority_resampled, y_minority_resampled = resample(X_minority, y_minority, replace=True, \n",
    "                                                       n_samples=len(X_train[y_train == 0]), random_state=42)\n",
    "X_train_resampled = np.vstack((X_train[y_train == 0], X_minority_resampled))\n",
    "y_train_resampled = np.hstack((y_train[y_train == 0], y_minority_resampled))\n",
    "\n",
    "# Step 2: Train on Balanced Dataset\n",
    "balanced_results = {name: evaluate_model(model, X_train_resampled, y_train_resampled, X_test, y_test) for name, model in models.items()}\n",
    "\n",
    "# Step 3: Optimize Best Model (Assuming XGBoost performed best)\n",
    "best_model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", n_estimators=200, learning_rate=0.05)\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "optimized_results = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_best),\n",
    "    \"Precision\": precision_score(y_test, y_pred_best),\n",
    "    \"Recall\": recall_score(y_test, y_pred_best),\n",
    "    \"F1 Score\": f1_score(y_test, y_pred_best),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_pred_best)\n",
    "}\n",
    "\n",
    "# Display Results\n",
    "print(\"Imbalanced Dataset Results:\", imbalanced_results)\n",
    "print(\"Balanced Dataset Results:\", balanced_results)\n",
    "print(\"Optimized Model Results:\", optimized_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef4f6ea",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcca476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the trained model to a file\n",
    "# joblib.dump(model, 'best_lgbm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05084c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
